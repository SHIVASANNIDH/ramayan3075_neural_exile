# âš™ï¸ Ramayan 3075 â€” The Neural Exile
### ğŸš€ An AI-Powered Narrative Transformation Engine  
*Built by Shiva Sannidh â€” for the Pratilipi AI Engineer Assignment*

---

> â€œWhat if timeless epics could be reborn through artificial intelligence?â€

**Ramayan 3075** is a generative AI storytelling system that uses **LLM orchestration**, **prompt chaining**, and **structured emotional logic**  
to reimagine ancient narratives in futuristic worlds.

Unlike typical one-shot prompt systems, this project introduces a **modular story-generation pipeline** that merges:
- ğŸ§  **LLM Reasoning** â€” multi-stage generation (world â†’ characters â†’ beats â†’ scenes)
- ğŸ’¡ **Deterministic fallback** â€” reproducible creative runs
- ğŸ’¬ **Prompt templating** â€” reusable creative instruction sets
- ğŸ› ï¸ **Generative LT (Language Transformation)** â€” converts classic literature into coherent, emotionally aligned modern adaptations

---

## ğŸ§¬ Quick Summary
| Feature | Description |
|----------|-------------|
| **Architecture Type** | Generative LT (Language Transformation) |
| **Core Engine** | Python + OpenAI LLMs (gpt-4o-mini) |
| **Modes** | Deterministic & Dynamic (LLM) |
| **Innovation** | Multi-prompt chaining for emotionally stable story generation |
| **Output Format** | Auto-assembled Markdown Narrative |
| **Pipeline Steps** | World â†’ Characters â†’ Plot Beats â†’ Scenes â†’ Reflection |
| **AI Controls** | Guardrails for tone, structure, and thematic fidelity |

---

## ğŸ§  Demo Command
Generate a complete futuristic Ramayan story in one line:

```bash
python src/run_neural_exile.py --use-llm

Output Example:
ğŸ¤– Running in LLM mode (using OpenAI API)...
âœ… Story generated and saved to: outputs/story_output_llm_2025xxxxTxxxxZ.md


## ğŸ§© Generative LT Concept

**Generative LT (Language Transformation)** is the core method behind this system.  
It applies structured prompt engineering to translate **classical literature** into **contextually coherent modern narratives** while preserving:
- Emotional integrity
- Narrative structure
- Thematic consistency

Each transformation follows a reproducible chain:

Classic Source â†’ Context Mapping â†’ Prompt Chaining â†’ Emotional Reframing â†’ Output Synthesis
---

## âš™ï¸ Features
- **Two Generation Modes**
  - Deterministic (Offline, reproducible)
  - LLM-based (OpenAI API, prompt chaining)
- **Modular Pipeline:**  
  World â†’ Characters â†’ Beats â†’ Scenes 
- **Emotionally Grounded Outputs:**  
  Focused on sensory detail and moral choice
- **Clean Markdown Output:**  
  Auto-assembled and timestamped

---

## ğŸ§  System Architecture

ramayan3075_neural_exile/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ run_neural_exile.py        # orchestrator (main runner)
â”‚   â”œâ”€â”€ llm_utils.py               # OpenAI wrapper + retries/fallbacks
â”‚   â”œâ”€â”€ utils.py                   # helper utils (file I/O, parsing)
â”‚
â”œâ”€â”€ prompts/
â”‚   â”œâ”€â”€ world.txt                  # world prompt template
â”‚   â”œâ”€â”€ characters.txt             # characters prompt (fixed names)
â”‚   â”œâ”€â”€ beats.txt                  # beats prompt template
â”‚   â””â”€â”€ scenes.txt                 # scenes prompt template
â”‚
â”œâ”€â”€ outputs/                       # generated .md outputs (optionally ignored in git)
â”‚   â””â”€â”€ story_output_llm_YYYYMMDDT*.md
â”‚
â”œâ”€â”€ runs/                          # saved prompts/responses for provenance (optional)
â”‚   â””â”€â”€ run_YYYYMMDDT*.json
â”‚
â”œâ”€â”€ docs/
â”‚   â”œâ”€â”€ solution_documentation.md  # Approach diagram, design, challenges, future work
â”‚   â””â”€â”€ architecture.mmd           # Mermaid source (optional)
â”‚
â”œâ”€â”€ tests/                         # minimal smoke tests for CI (recommended)
â”‚   â””â”€â”€ test_pipeline.py
â”‚
â”œâ”€â”€ .env                           # local secrets (DO NOT commit)
â”œâ”€â”€ .gitignore
â”œâ”€â”€ README.md
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ Dockerfile
â”œâ”€â”€ docker-compose.yml
â””â”€â”€ .github/
    â””â”€â”€ workflows/
        â””â”€â”€ ci.yml

Input â†’ Template Load â†’ LLM or Deterministic Generation â†’ Post-Processing â†’ Markdown Assembly

Key Files:
| Path | Description |
|------|--------------|
| `src/run_neural_exile.py` | Main orchestration pipeline |
| `src/llm_utils.py` | OpenAI API helper with retries |
| `prompts/` | Structured templates for each stage |
| `outputs/` | Generated markdown outputs |
| `docs/solution_documentation.md` | Full project explanation & diagrams |

---

## ğŸš€ How to Run

### 1ï¸ Setup Environment
```bash
python -m venv venv
source venv/bin/activate   # Mac/Linux
venv\Scripts\activate      # Windows
pip install -r requirements.txt

### 2 Add API Key:

create a .env file:
  OPENAI_API_KEY=your_key_here


3ï¸âƒ£ Run the Pipeline
Deterministic mode:
```bash
python src/run_neural_exile.py
LLM mode:
```bash
python src/run_neural_exile.py --use-llm
4ï¸âƒ£ View Results
Open your generated story inside outputs/.


